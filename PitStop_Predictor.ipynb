{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "PitStop_Predictor.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfOJXfvdviTz"
      },
      "source": [
        "# Objective\n",
        "Build a binary classifier that given a sequence of lap times will predict if a pit-stop will happen or not the next lap .. in other words I call this project End-of-Stint-or-NOT\n",
        "\n",
        "Data Source:\n",
        "- Ergast Developer API: https://ergast.com/mrd/\n",
        "\n",
        "## Table of Content:\n",
        "* [Data Preparation](#Section1)\n",
        "    * [Import data](#section_1_1)\n",
        "    * [Pit Stop Table Transformation](#section_1_2)\n",
        "    * [Lap Times Table Transformation](#section_1_3)\n",
        "    * [Left Join New Pit-Stop with New Lap-Times](#section_1_4)\n",
        "    * [TBC](#section_1_5)\n",
        "    * [TBC](#section_1_6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EgBebpnviT_"
      },
      "source": [
        "## Data Preparation <a class=\"anchor\" id=\"Section1\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7Bp4BmnviUB"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56SAjSrzviUJ"
      },
      "source": [
        "### Import Data <a class=\"anchor\" id=\"section_1_1\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWfLQEkQviUK"
      },
      "source": [
        "laps_master = pd.read_csv('data/lap_times.csv')\n",
        "races_master = pd.read_csv('data/races.csv')\n",
        "quali_master = pd.read_csv('data/qualifying.csv')\n",
        "drivers_master = pd.read_csv('data/drivers.csv')\n",
        "constructors_master = pd.read_csv('data/constructors.csv')\n",
        "results_master = pd.read_csv('data/results.csv')\n",
        "circuits_master = pd.read_csv('data/circuits.csv')\n",
        "pits_master = pd.read_csv('data/pit_stops.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-AtbRc4viUO"
      },
      "source": [
        "pits_master"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMTHQZGKviUW"
      },
      "source": [
        "### Pit Stop Table Transformation <a class=\"anchor\" id=\"section_1_2\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R501PuwUviUa"
      },
      "source": [
        "Create new data frame with a list of laps when a pit stop was occuring for each driver, for each race"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oTsyhkTviUb"
      },
      "source": [
        "pits_df_new = pits_master.groupby(['raceId', 'driverId'])['lap'].apply(list).reset_index(name='laps_when_pitstop')\n",
        "pits_df_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1NWU8NUviUe"
      },
      "source": [
        "#### Preview the lap times table\n",
        "Let's take a look at a random race, and random driver, and see how the lap times look .. just to better understand what transformation needs to be done on the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuG-MyirviUf"
      },
      "source": [
        "laps_master[laps_master.raceId == 841][laps_master.driverId == 17]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8UwGIRQviUq"
      },
      "source": [
        "### Lap Times Table Transformation <a class=\"anchor\" id=\"section_1_3\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qC8NZj65viUs"
      },
      "source": [
        "Create a new data frame containing a list of all the lap times in one row, for an entire race, for each driver"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0Ne8vybviUt"
      },
      "source": [
        "laps_df_new = laps_master.groupby(['raceId', 'driverId'])['milliseconds'].apply(list).reset_index(name='race_lap_times')\n",
        "laps_df_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYYgZ9gaviU2"
      },
      "source": [
        "### Left Join New Pit-Stop Table with New Lap-Times Table <a class=\"anchor\" id=\"section_1_4\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxYgHkkIviU3"
      },
      "source": [
        "merged = pd.merge(pits_df_new, laps_df_new, on=['raceId', 'driverId'], how='left')\n",
        "merged"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQZZA682viU-"
      },
      "source": [
        "### Lap Times Before Pit-Stop Sequence Partitioning <a class=\"anchor\" id=\"section_1_5\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0GUFzdEviU_"
      },
      "source": [
        "def partition_lapTime_into_sequences(pitStop_laps, race_lapTimes):\n",
        "    # NOTE: no need to return the last stint, since it is not followed by a pit stop... \n",
        "    #       only return sequence of lap times that are followed by a pit stop\n",
        "\n",
        "    # returns: list of lap time sequences (which as lists) ... so list of lists\n",
        "    \n",
        "    # remove pit stops from first lap... those occur because of a collision, so they should not be looked at when predicting the end of the stint\n",
        "    if 1 in pitStop_laps:\n",
        "        pitStop_laps = pitStop_laps[1:]                        # remove first lap pit stop, as it was not a regular, planned one\n",
        "        race_lapTimes = race_lapTimes[1:]                      # remove the first lap time, since the stint was \"corrupted\" by the emergency pitstop \n",
        "        pitStop_laps[:] = [x - 1 for x in pitStop_laps]        # subtract one lap from the pit-stop lap count, to account for the first lap being removed\n",
        "    \n",
        "    if len(pitStop_laps) < 1:\n",
        "        return np.nan    # no real stints have occured. Pitted on lap 1, then never pitted again during the race.\n",
        "    \n",
        "    sequences = []\n",
        "    prev_pit = pitStop_laps[0]\n",
        "    \n",
        "    if len(pitStop_laps) == 1:   # if the race is a one-stop race \n",
        "        sequences.append(race_lapTimes[:prev_pit-1])   # the off-by-one accounts for not taking into consideration the lap with the pit-stop as part of the sequence\n",
        "    else:                      # multi-stop race as\n",
        "        \n",
        "        for current_pit in pitStop_laps:\n",
        "            if current_pit == prev_pit:           # this is only true when prev_pit = pitStop_laps[0]\n",
        "                sequences.append(race_lapTimes[:current_pit-1])         # create first stint\n",
        "                # the off-by-one accounts for not taking into consideration the lap with the pit-stop as part of the sequence\n",
        "            else:\n",
        "                sequences.append(race_lapTimes[prev_pit:current_pit-1]) # create next sequence from (prev-pit-lap, current_pit-lap)\n",
        "                prev_pit = current_pit                             # update pointer to previous pit ... this will be needed for the next pit\n",
        "    return sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NoZX7a-viVD"
      },
      "source": [
        "### Sequencing Function Test cases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXJDjK99viVL"
      },
      "source": [
        "sample_input_pits = merged.iloc[13, :].laps_when_pitstop\n",
        "sample_input_lapTimes = merged.iloc[13, :].race_lap_times\n",
        "\n",
        "print(\"input pits: \", sample_input_pits)\n",
        "print(\"input laps: \", sample_input_lapTimes)\n",
        "\n",
        "print(\"output: \", partition_lapTime_into_sequences(sample_input_pits, sample_input_lapTimes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKkVAqmXviVb"
      },
      "source": [
        "To DO: write test cases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvJZ-v77B9Ej"
      },
      "source": [
        "### Get Lap Times of Final Stint (as a non-pit-stint)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dK-CTMKcB8aO"
      },
      "source": [
        "def get_last_stint_lap_times(pitStop_laps, race_lapTimes):\n",
        "    # returns the last stint's lap times, since it is not followed by a pit stop .. so it is non-pit-stop stint \n",
        "\n",
        "    last_pit = pitStop_laps[-1]\n",
        "    return race_lapTimes[last_pit:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMwKo-auEAzJ"
      },
      "source": [
        "### Test get_last_stint_lap_times function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMT607f0D1Yt"
      },
      "source": [
        "sample_input_pits = merged.iloc[13, :].laps_when_pitstop\n",
        "sample_input_lapTimes = merged.iloc[13, :].race_lap_times\n",
        "\n",
        "print(\"input pits: \", sample_input_pits)\n",
        "print(\"input laps: \", sample_input_lapTimes)\n",
        "\n",
        "print(\"output: \", get_last_stint_lap_times(sample_input_pits, sample_input_lapTimes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYvSnBM5EF2L"
      },
      "source": [
        "sample_input_pits = merged.iloc[1, :].laps_when_pitstop\n",
        "sample_input_lapTimes = merged.iloc[1, :].race_lap_times\n",
        "\n",
        "print(\"input pits: \", sample_input_pits)\n",
        "print(\"input laps: \", sample_input_lapTimes)\n",
        "\n",
        "print(\"output: \", get_last_stint_lap_times(sample_input_pits, sample_input_lapTimes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pyVIEUqviVb"
      },
      "source": [
        "### Apply sequence partitioning function the merged data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKdX0sJ3viVc"
      },
      "source": [
        "merged['stints'] = merged.apply(lambda x: partition_lapTime_into_sequences(x.laps_when_pitstop, x.race_lap_times), axis=1)\n",
        "merged['last_stint'] = merged.apply(lambda x: get_last_stint_lap_times(x.laps_when_pitstop, x.race_lap_times), axis=1)\n",
        "merged"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abv2v6MnviVt"
      },
      "source": [
        "Check if there are any missing stints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGOJv_91viVu"
      },
      "source": [
        "merged.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_lzs4aBviV3"
      },
      "source": [
        "There are some missing values based on the sequence partitioning transformation that we have just applied. Let's see where they are."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MysculrviV6"
      },
      "source": [
        "merged[merged.isnull().any(axis=1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fDEVnC5viWD"
      },
      "source": [
        "As I have thought, all cases are just races when there was only one pit stop, on lap 1, so for the scope of this end-of-stint classifier we can safely remove theses cases, as they do not affect the task at hand"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AdzLnXcviWF"
      },
      "source": [
        "merged = merged.dropna()\n",
        "merged"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUJG9BtkviWL"
      },
      "source": [
        "end_of_stint_sequences = merged['stints']\n",
        "end_of_stint_sequences[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4WRmxcQFk0L"
      },
      "source": [
        "last_stint_sequences = merged['last_stint']\n",
        "last_stint_sequences[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAj46HLHviWW"
      },
      "source": [
        "We need to flatten the structure of the data. We need a list of lists, not a Pandas Series of lists of lists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpQYM2prviWX"
      },
      "source": [
        "temp = end_of_stint_sequences.tolist()  # lists of lists of lists\n",
        "print(\"Before:\", temp[0:3])\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDQRmBd4_SlR"
      },
      "source": [
        "# Use list.extend() to convert a a 3D list to a 2D lists\n",
        "end_of_stint_sequences = []\n",
        "for elem in temp:\n",
        "    end_of_stint_sequences.extend(elem)       # this will make it lists of lists\n",
        "\n",
        "print(\"After:\", end_of_stint_sequences[0:3])\n",
        "print(\"Sample Size = \", len(end_of_stint_sequences))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKnQupWRviWc"
      },
      "source": [
        "### Generate not end of stint sequences --- this method did not work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xnehNa6viWc"
      },
      "source": [
        "My logic here is the following: Don't generate random laptimes, nor stints with random length.\n",
        "\n",
        "What I propose is: remove the last n laps from a real stint, and label it as a 'not-end-of-stint' kind of a sequence.\n",
        "\n",
        "The parameter n needs to be experimented with: we need to figure out what kind of experiment setup works best for our binary classifier. \n",
        "\n",
        "   - Initially what I am thinking is that I will remove the last lap, and create some fake samples... then remove the last 2 laps, and the last 4 laps, and create samples out of those too.\n",
        "   - What I want to make sure is to not create a very unbalanced data set. What I am aiming for is 20-25% end-of-stint data, with 75-80% not-end-of stint data to comprise my data set which I will use to train my binary classifier.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyRtmfrRviWd"
      },
      "source": [
        "def remove_lastN_elements(arr, N):\n",
        "    return arr[:-N]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOwtwBBw0gDK"
      },
      "source": [
        "print(end_of_stint_sequences[0])\n",
        "print()\n",
        "print(remove_lastN_elements(end_of_stint_sequences[0], 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P8s8uERviWu"
      },
      "source": [
        "NOT_end_of_stint_sequences = []\n",
        "\n",
        "# N needs to be experimented with. Initially I chose N=1, N=2, and N=4\n",
        "for lst in end_of_stint_sequences:\n",
        "    temp_list = remove_lastN_elements(lst, N = 1)        # remove last lap from each stint\n",
        "    NOT_end_of_stint_sequences.append(temp_list)\n",
        "    \n",
        "    temp_list = remove_lastN_elements(lst, N = 2)        # remove last 2 laps from each stint\n",
        "    NOT_end_of_stint_sequences.append(temp_list)\n",
        "    \n",
        "    temp_list = remove_lastN_elements(lst, N = 4)        # remove last 4 laps from each stint\n",
        "    NOT_end_of_stint_sequences.append(temp_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0Saff5tviWz"
      },
      "source": [
        "#print(len(NOT_end_of_stint_sequences))\n",
        "print(len(end_of_stint_sequences))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob9WKNuhviW3"
      },
      "source": [
        "RESULT = 3:1 ratio between not-end-of-stint and end-os-stint data\n",
        "\n",
        "Let's create the labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjcbeuNJviW4"
      },
      "source": [
        "end_of_stint_labels = [1] * len(end_of_stint_sequences)\n",
        "NOT_end_of_stint_labels = [0] * len(NOT_end_of_stint_sequences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KchdnRq7viXA"
      },
      "source": [
        "### Get NOT-end-of-stint sequences & Create final data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgjVmPo7HEkD"
      },
      "source": [
        "NOT_end_of_stint_sequences = last_stint_sequences.tolist() \n",
        "\n",
        "NOT_end_of_stint_labels = [0] * len(NOT_end_of_stint_sequences)\n",
        "end_of_stint_labels = [1] * len(end_of_stint_sequences)\n",
        "\n",
        "print(\"Labels:\")\n",
        "print(len(NOT_end_of_stint_labels))\n",
        "print(len(end_of_stint_labels))\n",
        "\n",
        "print(\"\\nSequences:\")\n",
        "print(len(NOT_end_of_stint_sequences))\n",
        "print(len(end_of_stint_sequences))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1AA3L8IviXD"
      },
      "source": [
        "stint_sequences = end_of_stint_sequences + NOT_end_of_stint_sequences\n",
        "stint_labels = end_of_stint_labels + NOT_end_of_stint_labels\n",
        "\n",
        "print(len(stint_sequences))\n",
        "print(len(stint_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmFEM3MvviXL"
      },
      "source": [
        "## Binary Classifier\n",
        "\n",
        "I view this task as a Sequence Classification task, where deep learning approaches have been widely used in practice for similar tasks such as: \n",
        "\n",
        " - DNA Sequence Classification: Given a DNA sequence of ACGT values, predict whether the sequence codes for a coding or non-coding region.\n",
        " - Anomaly Detection: Given a sequence of observations, predict whether the sequence is anomalous or not.\n",
        " - Sentiment Analysis: Given a sequence of text such as a review or a tweet, predict whether sentiment of the text is positive or negative.\n",
        " \n",
        "Reference: https://machinelearningmastery.com/sequence-prediction/\n",
        " \n",
        "I have done some research on the problem and the most common approaches seem to be using LSTM (Long-Short-Term-Memory) Recurrent Neural Networks. In the upcoming subsections I will test various architectures of different LSTM and maybe even non-LSTM Recurrent Neural Networks to see some results, then evaluate if we need to use some other binary classifier, or we actually just need more data, or better data, or we need to apply some techniques used when working with imbalaced data (undersampling, oversampling)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wlbg1Aes4DIp"
      },
      "source": [
        "### Split data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIHFVPByviXU"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(stint_sequences, stint_labels, test_size=0.20, random_state=7)\n",
        "\n",
        "print(\"Train set:\", len(X_train))\n",
        "print(\"Test set:\", len(X_test))\n",
        "print(\"Train labels:\", len(y_train))\n",
        "print(\"Test labels:\", len(y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2464ZwIM4Mai"
      },
      "source": [
        "### Pad Input Sequences "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MC_qyDohviXc"
      },
      "source": [
        "# find out what's the longest stint in our data set\n",
        "#max_stint_length = max(map(len, end_of_stint_sequences))\n",
        "#print(\"Max stint-length =\", max_stint_length)\n",
        "\n",
        "max_stint_length = 30 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGmgVkDXviXi"
      },
      "source": [
        "from keras.preprocessing import sequence\n",
        "\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_stint_length, padding=\"pre\", truncating='pre')\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_stint_length, padding=\"pre\", truncating='pre')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7oeyVm3BrHY"
      },
      "source": [
        "Wrap every list into numpy arrays, so Keras can process the input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH8dUFRqBpj7"
      },
      "source": [
        "X_train = np.array(X_train)\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "\n",
        "X_test = np.array(X_test)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "y_train = y_train.reshape(y_train.shape[0], 1)\n",
        "\n",
        "y_test = np.array(y_test)\n",
        "y_test = y_test.reshape(y_test.shape[0], 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhkuWQKqI1qk"
      },
      "source": [
        "testing the ratio of 0 to 1 in the train and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ROhVej7k626"
      },
      "source": [
        "unique, frequency = np.unique(y_test,  \n",
        "                              return_counts = True) \n",
        "# print unique values array \n",
        "print(\"Unique Values:\",  \n",
        "      unique) \n",
        "  \n",
        "# print frequency array \n",
        "print(\"Frequency Values:\", \n",
        "      frequency)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmQt3aRwC4Fx"
      },
      "source": [
        "unique, frequency = np.unique(y_train,  \n",
        "                              return_counts = True) \n",
        "# print unique values array \n",
        "print(\"Unique Values:\",  \n",
        "      unique) \n",
        "  \n",
        "# print frequency array \n",
        "print(\"Frequency Values:\", \n",
        "      frequency)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmIbguidviXL"
      },
      "source": [
        "### Approach 1: Simple LSTM for Sequence Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJBpgp9MviXN"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "np.random.seed(7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Alaw3JaaviXz"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(100, input_shape=(max_stint_length, 1)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74Ki7aT2M8A7"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(64, input_shape=(max_stint_length, 1), return_sequences=True))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKVY_AR_i5P1"
      },
      "source": [
        "### Approach 2: Time Distributed LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HkA0dexjWy1"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, TimeDistributed, LSTM, Dropout\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "np.random.seed(7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozfhF9pzicmn"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(512, input_shape=(max_stint_length, 1), return_sequences=True))\n",
        "#model.add(Dropout(0.3))\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
        "\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJK426bhmatW"
      },
      "source": [
        "### Approach 3: Bidirectional LSTMs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS8_N0jCmZvX"
      },
      "source": [
        "from keras.layers import Bidirectional\n",
        "\n",
        "# define LSTM model\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=(max_stint_length, 1)))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "#model.add(Dropout(0.2))\n",
        "#model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "#model.add(Bidirectional(LSTM(64)))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szfxV_bGsotK"
      },
      "source": [
        "### Approach 4: LSTM and CNNs combined"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLOcwPtGspLB"
      },
      "source": [
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=256, kernel_size=3, padding='same', activation='relu', input_shape=(max_stint_length, 1)))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}